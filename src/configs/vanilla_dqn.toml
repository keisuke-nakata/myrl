n_warmup_steps = 50000
# n_warmup_steps = 100
n_total_steps = 50000000
n_total_episodes = 600
n_stack_frames = 4

result_dir = "results/{env_id}/{now}"


[replay]
limit = 1000000


[policy]

[policy.params]
initial_epsilon = 1.0
# initial_epsilon = 0.1
final_epsilon = 0.1
final_exploration_step = 1000000


[optimizer]
optimizer = "RMSprop"

[optimizer.params]
lr = 0.00025
alpha = 0.95
eps = 0.01


[learner]
gamma = 0.99
batch_size = 32
target_network_update_freq = 10000
# target_network_update_soft = 0.01

[actor]
n_action_repeat = 4
n_random_actions_at_reset = [0, 30]  # will be converted to tuple

[history]
render_episode_freq = 25  # 0: no rendering
# render_episode_freq = 3  # 0: no rendering
